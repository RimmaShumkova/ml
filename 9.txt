Задача классификации. Алгоритмы классификации в ML. Проблема дисбаланса классов и ее решение. Методы сэмплирования. Метрики оценки классификации. Ошибки классификации.

Классификация — раздел ML, посвящённый задаче построения алгоритма, классифицирующего произвольный объект на основе информации, полученной из обучающей выборки. Алгоритм, осуществляющий классификацию, называется классификатором. 
Алгоритмы классификации можно разделить на две категории: 
Линейные модели классификации: 
- Логистическая регрессия (Logistic Regression) 
- Линейный дискриминантный анализ (Linear Discriminant Analysis, LDA) 
- Машины опорных векторов (Support Vector Machines, SVM) 
Нелинейные модели классификации:
- Метод k-ближайших соседей (k-Nearest Neighbors, k-NN) 
- Наивный байесовский метод (Naive Bayes) 
- Ядро SVM (Kernel SVM) 
- Классификатор дерева решений (Decision Tree Classifier) 
- Случайный лес (Random Forests Classification) 
Проблема дисбаланса классов. Метрика Accuracy бесполезна в задачах с неравными, или несбалансированными классами (imbalanced class). Как вариант — можно исправить с помощью алгоритмов сэмплирования. 
Сэмплирование (англ. data sampling) — метод корректировки обучающей выборки с целью балансировки распределения классов в исходном наборе данных. Когда в обучающем наборе данных доля примеров некоторого класса слишком мала, такие классы называются миноритарными (англ. minority), другие, со слишком большим количеством представителей, — мажоритарными (англ. majority). 
Методы сэмплирования:
1)	Субдискретизация (англ. under-sampling) — удаление некоторого количества примеров мажоритарного класса. 
2)	Передискретизация (англ. over-sampling) — увеличение количества примеров миноритарного класса. Комбинирование (англ. combining over- and under-sampling) — последовательное применение субдискретизации и передискретизации. 
3)	Ансамбль наборов (англ. ensemble balanced sets) — метод, при котором в процессе формирования ансамблей классификаторов применяются встроенные методы сэмплирования для достижения более равномерного распределения классов в обучающих выборках.
Метрики оценки классификации: матрица ошибок (Confusion Matrix), точность, правильность, F1-мерa, ROC-кривая.
В задаче классификации возможны две основные ошибки: 
1.	Ошибка первого рода (False Positive, FP): 
Модель ошибочно классифицирует отрицательный класс как положительный. 
2.	Ошибка второго рода (False Negative, FN): 
Модель ошибочно классифицирует положительный класс как отрицательный.
