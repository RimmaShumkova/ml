Основные понятия ML. Обучающая, валидационная и тестовая выборки. Кросс-валидация. Сравнительная характеристика методов k-fold и holdout.

Главные компоненты ML — данные, признаки и алгоритмы. 
ДАННЫЕ, ПРИЗНАКИ — переменные, которые описывают отдельные характеристики объекта, важные для обучения.
АЛГОРИТМЫ, или МОДЕЛИ — методы решения задачи. От выбора метода зависит точность, скорость работы и размер готовой модели.
ОБУЧАЮЩАЯ ВЫБОРКА (training set). Конечный набор объектов x, для которых известны значения целевой переменной y, т.е. все данные с известными ответами называются обучающей выборкой.
Обучающая выборка может быть разбита на несколько частей: 
➤ Тренировочная выборка: используется непосредственно для обучения модели. 
➤ Валидационная выборка: используется для настройки гиперпараметров и проверки качества модели в процессе обучения. 
➤ Тестовая выборка: используется для окончательной оценки производительности модели на данных, которые не были использованы в процессе обучения. 
Кросс-валидация (cross-validation) — это метод оценки обобщающей способности модели машинного обучения с помощью многократного разбиения обучающей выборки на подмножества («фолды»). Основная идея — несколько раз обучить модель на одной части данных и проверить её на другой, чтобы получить более надёжную оценку качества.

Сравнение Hold-out и K-fold кросс-валидации
Разбиение данных
Hold-out: Однократное разбиение на обучающую (train) и валидационную (и/или тестовую) выборки.
K-fold кросс-валидация: Многократное разбиение на K непересекающихся фолдов, где каждый фолд по очереди становится тестовой выборкой.

Стабильность оценки
Hold-out: Низкая стабильность — результат сильно зависит от случайного разбиения.
K-fold: Высокая стабильность — усреднение по K прогонам сглаживает случайные колебания.

Смещение (bias)
Hold-out: Может быть высоким, особенно если тестовая выборка нерепрезентативна.
K-fold: Смещение ниже, так как каждая точка данных участвует и в обучении, и в тестировании.

Дисперсия (variance)
Hold-out: Высокая дисперсия — оценки сильно варьируются при изменении random seed.
K-fold: Дисперсия ниже благодаря усреднению результатов.

Вычислительная сложность
Hold-out: Низкая — требуется одна тренировка и одна проверка.
K-fold: Высокая — необходимо K раз обучить и проверить модель.

Время обучения
Hold-out: Быстрое выполнение.
K-fold: Медленнее в K раз по сравнению с Hold-out.